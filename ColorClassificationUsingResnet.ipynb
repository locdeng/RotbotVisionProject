{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO17dyV9FlRKUZG282lJuQ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/locdeng/RotbotVisionProject/blob/main/ColorClassificationUsingResnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjft-RKYcpP2"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "XlDuq_Zqc1vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "#Define the ColorDataset class\n",
        "class ColorDataset(Dataset):\n",
        "    def __init__(self, base_dir, transform=None, train=True, split_ratio=0.8, seed=42):\n",
        "        self.base_dir = base_dir\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        self.split_ratio = split_ratio\n",
        "        self.seed = seed\n",
        "        self.classes = sorted(os.listdir(base_dir))\n",
        "        self.num_classes = len(self.classes)\n",
        "\n",
        "        # Create a list to store the paths of all images\n",
        "        self.all_images = []\n",
        "        for i, color_class in enumerate(self.classes):\n",
        "            class_path = os.path.join(base_dir, color_class)\n",
        "            images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
        "            self.all_images.extend([(img, i) for img in images])  # (image path, class index)\n",
        "\n",
        "        # Randomly shuffle the list of images\n",
        "        random.seed(seed)\n",
        "        random.shuffle(self.all_images)\n",
        "\n",
        "        # Split the dataset into training and testing sets\n",
        "        split_idx = int(len(self.all_images) * split_ratio)\n",
        "        if self.train:\n",
        "            self.images = self.all_images[:split_idx]\n",
        "        else:\n",
        "            self.images = self.all_images[split_idx:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path, label = self.images[index]\n",
        "\n",
        "        try:\n",
        "            print(f\"Loading image: {img_path}\")\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            if self.transform is not None:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image, label\n",
        "        except (OSError, PIL.UnidentifiedImageError) as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            return None, None\n",
        "\n",
        "#Define the transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "#Create an instance of the ColorDataset\n",
        "base_dir = '/content/gdrive/MyDrive/color'\n",
        "color_dataset = ColorDataset(base_dir, transform=transform_train, train=True)\n",
        "\n",
        "#Create a DataLoader\n",
        "color_loader = DataLoader(color_dataset, batch_size=32, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "xduRVPJPc4Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Load pre-trained ResNet-18 and ResNet-50 models\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "# Set the models to evaluation mode\n",
        "resnet18.eval()\n",
        "resnet50.eval()"
      ],
      "metadata": {
        "id": "x_ve72cEdIWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Modify the last fully connected layer for multi-color classification\n",
        "num_classes = len(color_dataset.classes)\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
        "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet18 = resnet18.to(device)\n",
        "resnet50 = resnet50.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_resnet18 = optim.Adam(resnet18.parameters(), lr=0.001)\n",
        "optimizer_resnet50 = optim.Adam(resnet50.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, criterion, optimizer, dataloader, num_epochs=10):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            if inputs is None or labels is None:\n",
        "                continue\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss.append(running_loss / len(dataloader))\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss[-1]}')\n",
        "\n",
        "    # Plotting training loss\n",
        "    plt.plot(epoch_loss, label='Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "# Train the ResNet18 model\n",
        "train_loss_resnet18 = train_model(resnet18, criterion, optimizer_resnet18, color_loader, num_epochs=10)\n",
        "# Save the trained ResNet18 model\n",
        "torch.save(resnet18.state_dict(), '/content/resnet18_color_classification.pth')\n",
        "# Train the ResNet50 model\n",
        "train_loss_resnet50 = train_model(resnet50, criterion, optimizer_resnet50, color_loader, num_epochs=10)\n",
        "# Save the trained ResNet50 model\n",
        "torch.save(resnet50.state_dict(), '/content/resnet50_color_classification.pth')"
      ],
      "metadata": {
        "id": "Xj5fLKszdL0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss_resnet18, label='ResNet18 Training Loss')\n",
        "plt.plot(train_loss_resnet50, label='ResNet50 Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Comparison Between ResNet18 and ResNet50')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pwwaNfafdY3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Evaluating\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    classification_report_str = classification_report(all_labels, all_predictions)\n",
        "    confusion_mat = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    return accuracy, classification_report_str, confusion_mat\n",
        "\n",
        "# Evaluate the ResNet18 model\n",
        "accuracy_resnet18, report_resnet18, confusion_mat_resnet18 = evaluate_model(resnet18, color_loader)\n",
        "print(f\"ResNet18 Accuracy: {accuracy_resnet18:.4f}\")\n",
        "print(\"Classification Report (ResNet18):\")\n",
        "print(report_resnet18)\n",
        "print(\"Confusion Matrix (ResNet18):\")\n",
        "print(confusion_mat_resnet18)\n",
        "\n",
        "# Evaluate the ResNet50 model\n",
        "accuracy_resnet50, report_resnet50, confusion_mat_resnet50 = evaluate_model(resnet50, color_loader)\n",
        "print(f\"\\nResNet50 Accuracy: {accuracy_resnet50:.4f}\")\n",
        "print(\"Classification Report (ResNet50):\")\n",
        "print(report_resnet50)\n",
        "print(\"Confusion Matrix (ResNet50):\")\n",
        "print(confusion_mat_resnet50)\n",
        "\n",
        "# Compare the results\n",
        "if accuracy_resnet18 > accuracy_resnet50:\n",
        "    print(\"\\nResNet18 performs better.\")\n",
        "elif accuracy_resnet18 < accuracy_resnet50:\n",
        "    print(\"\\nResNet50 performs better.\")\n",
        "else:\n",
        "    print(\"\\nBoth models have similar performance.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yxeEezzlddZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Visualize the results in a bar chart\n",
        "labels = ['ResNet18', 'ResNet50']\n",
        "accuracies = [accuracy_resnet18, accuracy_resnet50]\n",
        "\n",
        "plt.bar(labels, accuracies, color=['blue', 'orange'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of ResNet18 and ResNet50 Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "saEVVWc-dga7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Create ResNet18 model\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "# Modify the final fully connected layer for color classification\n",
        "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
        "\n",
        "# Load the trained weights\n",
        "checkpoint_path = '/content/resnet50_color_classification.pth'\n",
        "# checkpoint_path = '/content/resnet18_color_classification.pth'\n",
        "resnet50.load_state_dict(torch.load(checkpoint_path))\n",
        "resnet50 = resnet18.to(device)\n",
        "resnet50.eval()\n",
        "\n",
        "# Preprocess the input image\n",
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "\n",
        "    return input_image\n",
        "\n",
        "image_path = # test image result\n",
        "input_image = preprocess_image(image_path)\n",
        "\n",
        "# Pass the input through the model\n",
        "with torch.no_grad():\n",
        "    output = resnet18(input_image)\n",
        "\n",
        "# Get the predicted class index\n",
        "_, predicted_class_idx = torch.max(output, 1)\n",
        "\n",
        "# Map the predicted class index to the corresponding color class\n",
        "predicted_color = color_dataset.classes[predicted_class_idx.item()]\n",
        "\n",
        "# Print information\n",
        "image =cv2.imread('image_path')\n",
        "cv2_imshow(image)\n",
        "print(f\"Predicted color: {predicted_color}\")"
      ],
      "metadata": {
        "id": "okQE4Pv5doon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}